{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CijQdfOFUH_e",
        "outputId": "ce57f8b0-ec1e-482b-c592-006ace1e2a4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
            "Training veri seti versiyonu: v0.2\n",
            "Development veri seti versiyonu: v0.2\n",
            "Training veri setinde toplam 756 başlık mevcut.\n",
            "Development veri setinde toplam 85 başlık mevcut.\n"
          ]
        }
      ],
      "source": [
        "# 1. Gerekli kütüphanelerin yüklenmesi\n",
        "!pip install faiss-cpu numpy pandas tqdm\n",
        "!pip install openai==0.28\n",
        "\n",
        "# 2. Gerekli kütüphanelerin import edilmesi\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import faiss\n",
        "import openai\n",
        "\n",
        "# 3. OpenAI API anahtarını ayarla\n",
        "openai.api_key = \"\"\n",
        "\n",
        "# 4. Veri dosyalarının yüklenmesi\n",
        "train_file_path = \"/content/sample_data/final_train_data_v2.json\"\n",
        "dev_file_path = \"/content/sample_data/final_dev_data_v2.json\"\n",
        "\n",
        "# Dosyaların mevcut olup olmadığını kontrol edelim\n",
        "assert os.path.exists(train_file_path), \"Train dosyası bulunamadı!\"\n",
        "assert os.path.exists(dev_file_path), \"Dev dosyası bulunamadı!\"\n",
        "\n",
        "# 5. JSON dosyasını yükleyelim ve inceleyelim\n",
        "with open(train_file_path, \"r\", encoding=\"utf-8\") as train_file:\n",
        "    train_data = json.load(train_file)\n",
        "\n",
        "with open(dev_file_path, \"r\", encoding=\"utf-8\") as dev_file:\n",
        "    dev_data = json.load(dev_file)\n",
        "\n",
        "# 6. Veri yapısını inceleme\n",
        "print(f\"Training veri seti versiyonu: {train_data['version']}\")\n",
        "print(f\"Development veri seti versiyonu: {dev_data['version']}\")\n",
        "print(f\"Training veri setinde toplam {len(train_data['data'])} başlık mevcut.\")\n",
        "print(f\"Development veri setinde toplam {len(dev_data['data'])} başlık mevcut.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itA1pnnUXID6",
        "outputId": "86f9157e-3660-4e3c-d0b2-9b6aa130d4a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding oluşturuluyor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Data: 100%|██████████| 756/756 [07:45<00:00,  1.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding işlemi tamamlandı!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# 7. Her paragraf için embedding oluşturma\n",
        "def generate_embedding(text):\n",
        "    \"\"\"OpenAI API ile metni embedding'e çevirir.\"\"\"\n",
        "    response = openai.Embedding.create(\n",
        "        model=\"text-embedding-ada-002\",  # Uygun fiyatlı embedding modeli\n",
        "        input=[text]  # input parametresi bir liste olmalı\n",
        "    )\n",
        "    return response['data'][0]['embedding']  # İlk embedding'i döndür\n",
        "\n",
        "# 8. Eğitim verilerini embedding'e çevirme\n",
        "train_embeddings = []  # Bu listeye embedding'ler ekleyeceğiz\n",
        "\n",
        "print(\"Embedding oluşturuluyor...\")\n",
        "for topic in tqdm(train_data['data'], desc=\"Training Data\"):\n",
        "    for paragraph in topic['paragraphs']:\n",
        "        embedding = generate_embedding(paragraph['context'])  # Paragrafın embedding'ini al\n",
        "        train_embeddings.append(embedding)\n",
        "\n",
        "# 9. Embedding'leri NumPy formatında saklayalım\n",
        "train_embeddings_array = np.array(train_embeddings)\n",
        "np.save(\"/content/sample_data/train_embeddings.npy\", train_embeddings_array)\n",
        "print(\"Embedding işlemi tamamlandı!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLKEvjWLf979",
        "outputId": "f609c595-c390-42d0-cb2b-8a2735be50f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS dizinine 2400 embedding eklendi.\n",
            "FAISS dizini kaydedildi!\n"
          ]
        }
      ],
      "source": [
        "# 10. FAISS dizini oluşturma\n",
        "dimension = train_embeddings_array.shape[1]  # Embedding boyutu\n",
        "index = faiss.IndexFlatL2(dimension)  # L2 normuna göre arama\n",
        "index.add(train_embeddings_array)  # Embedding'leri FAISS'e ekle\n",
        "\n",
        "print(f\"FAISS dizinine {index.ntotal} embedding eklendi.\")\n",
        "\n",
        "# FAISS dizinini saklayalım\n",
        "faiss.write_index(index, \"/content/sample_data/faiss_index.bin\")\n",
        "print(\"FAISS dizini kaydedildi!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL8sBmzxg9Tu",
        "outputId": "e5fe73d3-867d-4eaf-f11c-1b9cc4df9c05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sorguya uygun bulunan belgeler:\n",
            "1. Belge ID: 70, Mesafe: 0.20507335662841797\n",
            "2. Belge ID: 51, Mesafe: 0.22441300749778748\n",
            "3. Belge ID: 231, Mesafe: 0.23101171851158142\n",
            "4. Belge ID: 48, Mesafe: 0.23851671814918518\n",
            "5. Belge ID: 30, Mesafe: 0.24012857675552368\n"
          ]
        }
      ],
      "source": [
        "# Sorgu için embedding oluşturma ve FAISS kullanarak en yakın belgeleri bulma\n",
        "def retrieve_documents(query, k=5):\n",
        "    \"\"\"Kullanıcı sorgusu için en yakın k belgeyi döndürür.\"\"\"\n",
        "    query_embedding = np.array([generate_embedding(query)])\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "    return indices[0], distances[0]\n",
        "\n",
        "# Örnek bir sorgu\n",
        "query = \"Osman Bey ne zaman doğmuştur?\"\n",
        "indices, distances = retrieve_documents(query)\n",
        "\n",
        "print(\"Sorguya uygun bulunan belgeler:\")\n",
        "for i, idx in enumerate(indices):\n",
        "    print(f\"{i+1}. Belge ID: {idx}, Mesafe: {distances[i]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "YUsPxt1ahKpn"
      },
      "outputs": [],
      "source": [
        "def generate_fid_response(query, indices):\n",
        "    \"\"\"Fusion-in-Decoder ile bağlamlı yanıt oluşturur.\"\"\"\n",
        "    # Geçerli indeksleri filtreleme\n",
        "    valid_indices = [idx for idx in indices if 0 <= idx < len(train_data['data'])]\n",
        "    if not valid_indices:  # Eğer geçerli belge yoksa\n",
        "        return \"Belge bulunamadı.\"\n",
        "\n",
        "    # Alınan belgeleri birleştirme\n",
        "    context = \"\\n\".join([train_data['data'][idx]['paragraphs'][0]['context'] for idx in valid_indices])\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Lütfen yalnızca tek veya iki kelimelik yanıtlar ver. Örneğin: 'Osman' gibi.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Kontekst: {context}\\nSoru: {query}\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "    return response['choices'][0]['message']['content']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Rud6zYjGzh5w"
      },
      "outputs": [],
      "source": [
        "def generate_fid_response_long(query, indices):\n",
        "    \"\"\"Fusion-in-Decoder ile bağlamlı yanıt oluşturur.\"\"\"\n",
        "    # Geçerli indeksleri filtreleme\n",
        "    valid_indices = [idx for idx in indices if 0 <= idx < len(train_data['data'])]\n",
        "    if not valid_indices:  # Eğer geçerli belge yoksa\n",
        "        return \"Belge bulunamadı.\"\n",
        "\n",
        "    # Alınan belgeleri birleştirme\n",
        "    context = \"\\n\".join([train_data['data'][idx]['paragraphs'][0]['context'] for idx in valid_indices])\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Lütfen doğru ve tam yanıtlar ver.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Kontekst: {context}\\nSoru: {query}\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "    return response['choices'][0]['message']['content']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG12s1mGpn_r",
        "outputId": "22bfef30-8b98-429c-c9ef-16a495fcbbe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soru: Osman Bey nerede doğmuştur?\n",
            "Yanıt: Bilecik\n"
          ]
        }
      ],
      "source": [
        "# Örnek bir test sorusu\n",
        "query = \"Osman Bey nerede doğmuştur?\"\n",
        "\n",
        "# Retriever'dan bağlamı al\n",
        "indices, distances = retrieve_documents(query)\n",
        "\n",
        "# Bağlamdan yanıt oluştur\n",
        "response = generate_fid_response(query, indices)\n",
        "\n",
        "# Sonucu yazdır\n",
        "print(\"Soru:\", query)\n",
        "print(\"Yanıt:\", response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Z1irQH-KumnO"
      },
      "outputs": [],
      "source": [
        "def normalize_text(text):\n",
        "    import string\n",
        "    text = text.lower().strip()\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN2tkGItiRdY",
        "outputId": "3647f5d6-346f-4e82-a449-ec9a9c1fd698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test veri setinden 539 soru alındı.\n",
            "Tahminler üretiliyor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Questions: 100%|██████████| 539/539 [04:45<00:00,  1.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tüm tahminler üretildi.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Test veri setinden soruları alalım\n",
        "questions = [q['question'] for data in dev_data['data'] for q in data['paragraphs'][0]['qas']]\n",
        "references = [q['answers'][0]['text'] for data in dev_data['data'] for q in data['paragraphs'][0]['qas']]\n",
        "\n",
        "print(f\"Test veri setinden {len(questions)} soru alındı.\")\n",
        "\n",
        "# Tahminleri üretelim\n",
        "predictions = []\n",
        "\n",
        "print(\"Tahminler üretiliyor...\")\n",
        "for question in tqdm(questions, desc=\"Processing Questions\"):\n",
        "    indices, _ = retrieve_documents(question)  # Retriever\n",
        "    response = generate_fid_response(question, indices)  # Generator\n",
        "    predictions.append(response)\n",
        "\n",
        "print(\"Tüm tahminler üretildi.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "zjU5D70MuqJm"
      },
      "outputs": [],
      "source": [
        "# Normalize edilmiş tahminler ve referanslar\n",
        "normalized_predictions = [normalize_text(pred) for pred in predictions]\n",
        "normalized_references = [normalize_text(ref) for ref in references]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6ix7olGnhDT",
        "outputId": "2a462474-b7f7-4a21-f55d-7aa2e5ccabf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exact Match (EM): 3.90%\n",
            "F1 Score: 8.07%\n"
          ]
        }
      ],
      "source": [
        "def calculate_em_and_f1(predictions, references):\n",
        "    exact_match = 0\n",
        "    total_f1 = 0\n",
        "\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        # Exact Match\n",
        "        if pred.strip() == ref.strip():\n",
        "            exact_match += 1\n",
        "\n",
        "        # F1 Score\n",
        "        pred_tokens = set(pred.split())\n",
        "        ref_tokens = set(ref.split())\n",
        "        common_tokens = pred_tokens & ref_tokens\n",
        "        precision = len(common_tokens) / len(pred_tokens) if pred_tokens else 0\n",
        "        recall = len(common_tokens) / len(ref_tokens) if ref_tokens else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "        total_f1 += f1\n",
        "\n",
        "    exact_match_score = exact_match / len(references) * 100\n",
        "    f1_score_average = total_f1 / len(references) * 100\n",
        "    return exact_match_score, f1_score_average\n",
        "\n",
        "# EM ve F1 Score hesaplama\n",
        "em_score, f1_score = calculate_em_and_f1(normalized_predictions, normalized_references)\n",
        "print(f\"Exact Match (EM): {em_score:.2f}%\")\n",
        "print(f\"F1 Score: {f1_score:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcv7skb6oGqS",
        "outputId": "c4828ed7-4013-462d-abfd-04dd99a37c8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=c5fe5debfeccdb472e772c9c489b8ba0864deb529dd83e042f5d3a037ce21e05\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge-score nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG8b5S4noQy4",
        "outputId": "1dd4152a-9f3c-4bd0-9543-b87e3d132bf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROUGE-1: 10.19%\n",
            "ROUGE-2: 3.54%\n",
            "ROUGE-L: 10.15%\n",
            "BLEU: 6.78%\n"
          ]
        }
      ],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "from rouge_score import rouge_scorer\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "def calculate_rouge(predictions, references):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n",
        "\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        scores = scorer.score(ref, pred)\n",
        "        rouge_scores[\"rouge1\"].append(scores[\"rouge1\"].fmeasure)\n",
        "        rouge_scores[\"rouge2\"].append(scores[\"rouge2\"].fmeasure)\n",
        "        rouge_scores[\"rougeL\"].append(scores[\"rougeL\"].fmeasure)\n",
        "\n",
        "    # Ortalama ROUGE skorlarını hesapla\n",
        "    avg_rouge1 = sum(rouge_scores[\"rouge1\"]) / len(rouge_scores[\"rouge1\"]) * 100\n",
        "    avg_rouge2 = sum(rouge_scores[\"rouge2\"]) / len(rouge_scores[\"rouge2\"]) * 100\n",
        "    avg_rougeL = sum(rouge_scores[\"rougeL\"]) / len(rouge_scores[\"rougeL\"]) * 100\n",
        "\n",
        "    return avg_rouge1, avg_rouge2, avg_rougeL\n",
        "\n",
        "# ROUGE metriklerini hesapla\n",
        "rouge1, rouge2, rougeL = calculate_rouge(normalized_predictions, normalized_references)\n",
        "print(f\"ROUGE-1: {rouge1:.2f}%\")\n",
        "print(f\"ROUGE-2: {rouge2:.2f}%\")\n",
        "print(f\"ROUGE-L: {rougeL:.2f}%\")\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def calculate_bleu(predictions, references):\n",
        "    \"\"\"BLEU skorlarını hesaplar.\"\"\"\n",
        "    bleu_scores = []\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        pred_tokens = pred.split()\n",
        "        ref_tokens = [ref.split()]  # BLEU için doğru yanıt bir liste içinde olmalı\n",
        "        bleu_scores.append(sentence_bleu(ref_tokens, pred_tokens, weights=(1.0, 0.0, 0.0, 0.0)))  # BLEU-1\n",
        "    return sum(bleu_scores) / len(bleu_scores) * 100\n",
        "\n",
        "# BLEU metriklerini hesapla\n",
        "bleu_score = calculate_bleu(normalized_predictions, normalized_references)\n",
        "print(f\"BLEU: {bleu_score:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQGSrFiToUoa",
        "outputId": "eacaa977-2572-4736-afc1-6f4c04d39167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall@5: 1.67%\n"
          ]
        }
      ],
      "source": [
        "def calculate_recall_at_k(references, retriever_results, train_data, k=5):\n",
        "    \"\"\"Retriever'ın doğru bağlamı döndürme oranını hesaplar.\"\"\"\n",
        "    relevant = 0\n",
        "\n",
        "    for ref, results in zip(references, retriever_results):\n",
        "        # Retriever'ın döndürdüğü bağlamları al\n",
        "        contexts = [\n",
        "            train_data['data'][idx]['paragraphs'][0]['context']\n",
        "            for idx in results[:k] if 0 <= idx < len(train_data['data'])\n",
        "        ]\n",
        "        # Bağlamların doğru yanıtı içerip içermediğini kontrol et\n",
        "        if any(ref.lower() in context.lower() for context in contexts):\n",
        "            relevant += 1\n",
        "\n",
        "    recall = relevant / len(references) * 100\n",
        "    return recall\n",
        "\n",
        "# Retriever sonuçlarını al\n",
        "retriever_results = [retrieve_documents(question)[0] for question in questions]\n",
        "\n",
        "# Recall@5 hesapla\n",
        "recall_at_5 = calculate_recall_at_k(normalized_references, retriever_results, train_data, k=5)\n",
        "print(f\"Recall@5: {recall_at_5:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnuhtevOoXP4",
        "outputId": "8e528d56-8dfd-419a-c94a-c33137cfa0b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             Metric      Value\n",
            "0  Exact Match (EM)   3.896104\n",
            "1          F1 Score   8.068961\n",
            "2           ROUGE-1  10.189030\n",
            "3           ROUGE-2   3.539408\n",
            "4           ROUGE-L  10.146770\n",
            "5              BLEU   6.783776\n",
            "6          Recall@5   1.669759\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    \"Metric\": [\"Exact Match (EM)\", \"F1 Score\", \"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"BLEU\", \"Recall@5\"],\n",
        "    \"Value\": [em_score, f1_score, rouge1, rouge2, rougeL, bleu_score, recall_at_5]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZLvuiKPyV7g",
        "outputId": "844e4521-b963-4062-cd61-c06ca977c543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soru: Ertuğrul Bey kaç yaşında vefat etmiştir?\n",
            "Yanıt: Belge bulunamadı.\n"
          ]
        }
      ],
      "source": [
        "# Örnek bir test sorusu\n",
        "query = \"Ertuğrul Bey kaç yaşında vefat etmiştir?\"\n",
        "\n",
        "# Retriever'dan bağlamı al\n",
        "indices, distances = retrieve_documents(query)\n",
        "\n",
        "# Bağlamdan yanıt oluştur\n",
        "response = generate_fid_response_long(query, indices)\n",
        "\n",
        "# Sonucu yazdır\n",
        "print(\"Soru:\", query)\n",
        "print(\"Yanıt:\", response)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
